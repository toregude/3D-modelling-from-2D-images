%EVERYTHING HERE IS IMPLEMENTED WITH RESPECT TO THE KICKER PICTURES!
%Lot of inspiration gathered from here: https://se.mathworks.com/help/vision/ug/structure-from-motion-from-two-views.html

addpath('cv_functions');
addpath('colmap');

% Specify the path to the subfolder containing the images
subfolderPath = '.\kicker_dslr_undistorted\kicker\images\dslr_images_undistorted\';

% Get a list of all files and folders in the subfolder
files = dir(fullfile(subfolderPath, '*.JPG'));  % Modify the file extension as needed

% Preallocate an array to store the image file names
imageFiles = cell(numel(files), 1);

% Store the file names in the array
for i = 1:numel(files)
    imageFiles{i} = fullfile(subfolderPath, files(i).name);
end

%Calibration matrix for the kicker
K = [3410.34 0 3121.33;
    0 3409.98 2067.07;
    0 0 1];


%Matlab functions we should use:
% detectHarrisFeatures
% extractFeatures
% matchFeatures
% estgeotform3d
% cameraIntrinsics

for i = 1:size(imageFiles,1)-1 %-1 since we iterate over both i and i+1
    %Get the grayscale images i and i+1
    I1 = im2gray(imread(imageFiles{i}));
    I2 = im2gray(imread(imageFiles{i+1}));

    %Generate camera intrinsics
    focalLength = [3410.34 3409.98];
    principalPoint = [3121.33 2067.07];
    imageSize = size(I1);
    intrinsics = cameraIntrinsics(focalLength, principalPoint, imageSize);
    
    %Estimating K, just to see if it is feasible
    k = 1.25; %Chosen in the interval [0.5 2] is normal
    K_estimated = estimate_K(imageSize, k);
    focalLength_estimated = [K_estimated(1,1) K_estimated(1,1)];
    principalPoint_estimated = [K_estimated(1,3) K_estimated(2,3)];
    intrinsics_estimated = cameraIntrinsics(focalLength_estimated, principalPoint_estimated, imageSize);
    
    %Show the two pictures, trying to undistort
    I1_undistort = undistortImage(I1, intrinsics);
    I2_undistort = undistortImage(I2, intrinsics);
    figure
    imshowpair(I1_undistort, I2_undistort, "montage");
    title("Undistorted Images, real K");

    I1_undistort_estimated = undistortImage(I1, intrinsics_estimated);
    I2_undistort_estimated = undistortImage(I2, intrinsics_estimated);
    figure
    imshowpair(I1_undistort_estimated, I2_undistort_estimated, "montage");
    title("Undistorted Images, estimated K");
    
    %Utilize the estimated 

    %Detect feature points of first picture
    imagePoints1 = detectHarrisFeatures(I1);
    
    %Visualize detected points of first pic
    figure
    imshow(I1, InitialMagnification = 50);
    title("150 Strongest Corners from the First Image");
    hold on
    plot(selectStrongest(imagePoints1, 150));
    
    %Create the point tracker
    tracker = vision.PointTracker(MaxBidirectionalError=1, NumPyramidLevels=5);
    
    %Initialize the point tracker
    imagePoints1 = imagePoints1.Location;
    initialize(tracker, imagePoints1, I1);

    %Track the points
    [imagePoints2, validIdx] = step(tracker, I2);
    matchedPoints1 = imagePoints1(validIdx, :);
    matchedPoints2 = imagePoints2(validIdx, :);

    %Visualize correspondences
    figure
    showMatchedFeatures(I1, I2, matchedPoints1, matchedPoints2);
    title("Tracked Features");



    break
end

%%Display 3D point cloud and do some sort of best fit to this

% [F, epipolarInliers] = estimateFundamentalMatrix(...
% matchedPoints1, matchedPoints2, Confidence = 99.99);
% 
% %Trying to escape the fact that we do not know how to calibrate our camera?
% [U, S, V] = svd(F);
% s = (S(1,1) + S(2,2))/2;
% S = [s 0 0; 0 s 0; 0 0 0];
% E = U*S*V';
